{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CHAPTER 3. Metagenomes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install conda env and activate it**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "conda env create -f mags.yaml\n",
    "```\n",
    "\n",
    "```\n",
    "conda activate mags\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Disclaimer: This part of the work was performed on a university server. Hybrid metagenomic assembly using SPAdes and functional profiling using HUMAnN3 requires a LOT of RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 0. Install SPAdes v4.0.0 - the latest version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://github.com/ablab/spades/releases/download/v4.0.0/SPAdes-4.0.0-Linux.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tar -xzf SPAdes-4.0.0-Linux.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf SPAdes-4.0.0-Linux.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 1. Hybrid metagenomic assembly**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Assembly_pipeline` is a Snakemake pipeline that first conducts hybrid metagenomic assembly with `metaSPAdes` and then runs `MetaQuast` to assess the quality of the MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! snakemake -s Assembly_pipeline --cores all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result of this pipeline `MAGs` are stored in `MAGs_scaffolds` folder<br>\n",
    "And `MetaQuast` reports are stored in `metaquast_reports`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After careful evaluation of MetaQuast reports, we decided to filter out sequences shorter than 3500 nucleotides from the MAGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Filtering_pipeline` is a Snakemake pipeline that runs our self-written python script `scripts/filter_MAGs.py` through each of 10 MAGs. Snakemake pipeline allowed to perform it quickly and step-by-step. Also it was convenient in terms of storing output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! snakemake -s Filtering_pipeline --use-conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result of this pipeline `filtered MAGs` are stored in `filtered_MAGs` folder<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part 2. Functional profiling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2.1. Screening for antimicrobial resistance or virulence genes with `ABRicate`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2.1.1. Force update `CARD`, `ResFinder` & `VFDB` databases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Force update `CARD` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! abricate-get_db --db card --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Force update `ResFinder` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! abricate-get_db --db resfinder --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Force update `VFDB` database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! abricate-get_db --db vfdb --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2.1.2. Run `ABRicate`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ABRicate_pipeline` is a Snakemake pipeline that runs `ABRicate` against `CARD`, `ResFinder` & `VFDB` databases through all 10 filtered MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! snakemake -s ABRicate_pipeline --cores all --use-conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result of this pipeline outputs are stored in `ABRicate_results` folder:\n",
    "- `ABRicate_results/card`\n",
    "- `ABRicate_results/resfinder`\n",
    "- `ABRicate_results/vfdb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2.1.3. Parse `ABRicate` outputs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Part 2.1.3.1. Creating directories to store files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `ABRicate_results/summary/` folder where merged results will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ABRicate_results/summary/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `ABRicate_results/summary/txt` and `ABRicate_results/summary/tsv` folders where different file types of results will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ABRicate_results/summary/txt/\n",
    "! mkdir ABRicate_results/summary/tsv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Part 2.1.3.2. Merging multiple outputs (per sample) into summary (per database)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`CARD` database**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge 10 different results on `CARD` database into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! abricate --summary ABRicate_results/card/*.txt > ABRicate_results/summary/txt/card_summary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it to `.tsv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scripts/abr2tsv.py` does:\n",
    "- Converts `.txt` file to `.tsv`\n",
    "- Renames column `#FILE` to `SAMPLE`\n",
    "- Renames sample name from `ABRicate_results/{db}/{sample}_{db}.txt` to `{sample}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved to: ABRicate_results/summary/tsv/card_summary.tsv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# {path_to_script} {path_to_input_txt_file} {path_to_output_tsv_file}\n",
    "%run scripts/abr2tsv.py 'ABRicate_results/summary/txt/card_summary.txt' 'ABRicate_results/summary/tsv/card_summary.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ResFinder` database**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge 10 different results on `ResFinder` database into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! abricate --summary ABRicate_results/resfinder/*.txt > ABRicate_results/summary/txt/resfinder_summary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it to `.tsv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved to: ABRicate_results/summary/tsv/resfinder_summary.tsv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# {path_to_script} {path_to_input_txt_file} {path_to_output_tsv_file}\n",
    "%run scripts/abr2tsv.py 'ABRicate_results/summary/txt/resfinder_summary.txt' 'ABRicate_results/summary/tsv/resfinder_summary.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`VFDB` database**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge 10 different results on `VFDB` database into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! abricate --summary ABRicate_results/vfdb/*.txt > ABRicate_results/summary/txt/vfdb_summary.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert it to `.tsv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved to: ABRicate_results/summary/tsv/vfdb_summary.tsv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# {path_to_script} {path_to_input_txt_file} {path_to_output_tsv_file}\n",
    "%run scripts/abr2tsv.py 'ABRicate_results/summary/txt/vfdb_summary.txt' 'ABRicate_results/summary/tsv/vfdb_summary.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Part 2.1.3.3. Convert `ABRicate` summary output format into `presence` format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ABRicate` summary output is a simple matrix of gene presence/absence. An absent gene is denoted `.` and a present gene is represented by its `%COVERAGE`.<br>\n",
    "Yet while dealing with MAGs there could be more than 1 occurence of some gene. In that case ABRicate writes `100.00;100.00;99.94;100.00;100.00` into its cell.<br>\n",
    "However we are still interested in presence/abscence of genes. That is why we wrote `scripts/abr_tsv2presence.py` script that will change `.` into `minus` and whatever else into `plus` for the sake of convenience in further visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an `ABRicate_results/summary/presence/` folder where files will be stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir ABRicate_results/summary/presence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert `_summary.tsv` to `_presence.tsv` - `CARD` database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved to: ABRicate_results/summary/presence/card_presence.tsv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# {path_to_script} {path_to_input_summary_file} {path_to_output_presence_file}\n",
    "%run scripts/abr_tsv2presence.py 'ABRicate_results/summary/tsv/card_summary.tsv' 'ABRicate_results/summary/presence/card_presence.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert `_summary.tsv` to `_presence.tsv` - `ResFinder` database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved to: ABRicate_results/summary/presence/resfinder_presence.tsv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# {path_to_script} {path_to_input_summary_file} {path_to_output_presence_file}\n",
    "%run scripts/abr_tsv2presence.py 'ABRicate_results/summary/tsv/resfinder_summary.tsv' 'ABRicate_results/summary/presence/resfinder_presence.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert `_summary.tsv` to `_presence.tsv` - `VFDB` database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved to: ABRicate_results/summary/presence/vfdb_presence.tsv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# {path_to_script} {path_to_input_summary_file} {path_to_output_presence_file}\n",
    "%run scripts/abr_tsv2presence.py 'ABRicate_results/summary/tsv/vfdb_summary.tsv' 'ABRicate_results/summary/presence/vfdb_presence.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2.1.4. Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please open `RStudio` and go through  `ABRicate_heatmaps_journal.R` script.<br>\n",
    "There are a lot of manual adjustments to the plots to make it executable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2.1.5. Create a merged summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `merged_summary.tsv` file with the number of genes founds per sample in each of three databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only the SAMPLE and NUM_FOUND columns from each dataset\n",
    "card_df = pd.read_csv('ABRicate_results/summary/tsv/card_summary.tsv', sep='\\t', usecols=['SAMPLE', 'NUM_FOUND'])\n",
    "resfinder_df = pd.read_csv('ABRicate_results/summary/tsv/resfinder_summary.tsv', sep='\\t', usecols=['SAMPLE', 'NUM_FOUND'])\n",
    "vfdb_df = pd.read_csv('ABRicate_results/summary/tsv/vfdb_summary.tsv', sep='\\t', usecols=['SAMPLE', 'NUM_FOUND'])\n",
    "\n",
    "# Rename the NUM_FOUND columns to distinguish them\n",
    "card_df.rename(columns={'NUM_FOUND': 'card'}, inplace=True)\n",
    "resfinder_df.rename(columns={'NUM_FOUND': 'resfinder'}, inplace=True)\n",
    "vfdb_df.rename(columns={'NUM_FOUND': 'vfdb'}, inplace=True)\n",
    "\n",
    "# Merge the datasets on the SAMPLE column\n",
    "merged_df = card_df.merge(resfinder_df, on='SAMPLE').merge(vfdb_df, on='SAMPLE')\n",
    "\n",
    "# Save the merged dataset to a new TSV file\n",
    "merged_df.to_csv('ABRicate_results/summary/tsv/merged_summary.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Part 2.1.5.1. Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please open `RStudio` and go through  `ABRicate_barplots_journal.R` script.<br>\n",
    "There are a lot of manual adjustments to the plots to make it executable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2.2. Profiling microbial pathways with `HUMAnN3`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Disclaimer: it is important to install `HUMAnN3` properly with all the requirements and dependecies. <br>\n",
    "> Although `HUMAnN3` will be installed with `mags.yaml` conda envinronment it is also important to install all the databases needed. Please follow the official [installation guide](https://github.com/biobakery/humann?tab=readme-ov-file#initial-installation)<br>\n",
    "> In the `mags.yaml` `HUMAnN3` is already installed with `pip` so proceed to:\n",
    "> - **Download the ChocoPhlAn database:**\n",
    "> ```\n",
    "> humann_databases --download chocophlan full $INSTALL_LOCATION\n",
    "> ```\n",
    "> - **Download a translated search database:**\n",
    "> ```\n",
    "> humann_databases --download uniref uniref90_diamond $INSTALL_LOCATION\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2.2.1. Run `HUMAnN3`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Disclaimer: `HUMAnN3` could be run in `--bypass-prescreen` mode<br>\n",
    ">In this mode it bypasses the taxomonic profiling with `MetaPhlAn` step<br>\n",
    ">Yet we wanted to compare taxonomic identification with `MetaPhlAn` and `Kraken2`<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HUMAnN3_pipeline` is a Snakemake pipeline that runs `HUMAnN3` through all 10 filtered MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! snakemake -s HUMAnN3_pipeline --cores all --use-conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result of this pipeline outputs are stored in `HUMAnN3_results/by_samples` folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2.2.2. Parse results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Part 2.2.2.1. Path abundance files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `HUMAnN3_results/pathabundance_tables` folder to store all `pathabundance.tsv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir HUMAnN3_results/pathabundance_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy `HUMAnN3_results/by_samples/{sample}/{sample}_pathabundance.tsv` files to the `HUMAnN3_results/pathabundance_tables` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp HUMAnN3_results/by_samples/*/*_pathabundance.tsv HUMAnN3_results/pathabundance_tables/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all `pathabundance.tsv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! humann_join_tables --input HUMAnN3_results/pathabundance_tables/ --output HUMAnN3_results/HUMAnN3_merged_pathabundance.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter `HUMAnN3_results/HUMAnN3_merged_pathabundance.tsv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scripts/filt_humann3.py` does:\n",
    "- Deletes every row that contains `UNMAPPED`, `UNINTEGRATED`, `unclassified` (`MetaPhlAn` did not handle taxonomic profiling at all)\n",
    "- Renames column `# Pathway` to `Pathway`\n",
    "- Renames sample name from `{sample}_Abundance` to `{sample}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved to: HUMAnN3_results/pathabundance_filtered.tsv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# {path_to_script} {path_to_input_file} {path_to_output_file}\n",
    "%run scripts/filt_humann3.py 'HUMAnN3_results/HUMAnN3_merged_pathabundance.tsv' 'HUMAnN3_results/pathabundance_filtered.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize to relative abundance with  `total sum scaling (TSS)`-style normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading table from: HUMAnN3_results/pathabundance_filtered.tsv\n",
      "WARNING: Column 3 (D3) has zero sum at level 1\n",
      "WARNING: Column 7 (P3) has zero sum at level 1\n"
     ]
    }
   ],
   "source": [
    "! humann_renorm_table --input HUMAnN3_results/pathabundance_filtered.tsv --units relab --output HUMAnN3_results/pathabundance_filtered_normalized.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Part 2.2.2.2. Gene families files**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `HUMAnN3_results/genefamilies_tables` folder to store all `genefamilies.tsv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir HUMAnN3_results/genefamilies_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy `HUMAnN3_results/by_samples/{sample}/{sample}_genefamilies.tsv` files to the `HUMAnN3_results/genefamilies_tables/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp HUMAnN3_results/by_samples/*/*_genefamilies.tsv HUMAnN3_results/genefamilies_tables/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all `genefamilies.tsv` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! humann_join_tables --input HUMAnN3_results/genefamilies_tables/ --output HUMAnN3_results/HUMAnN3_merged_genefamilies.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter `HUMAnN3_results/HUMAnN3_merged_genefamilies.tsv` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scripts/filt_humann3.py` does:\n",
    "- Deletes every row that contains `UNMAPPED`, `UNINTEGRATED`, `unclassified` (`MetaPhlAn` did not handle taxonomic profiling at all)\n",
    "- Renames column `# Gene Family` to `Gene_Family`\n",
    "- Renames sample name from `{sample}-RPKs` to `{sample}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified file saved to: HUMAnN3_results/genefamilies_filtered.tsv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# {path_to_script} {path_to_input_file} {path_to_output_file}\n",
    "%run scripts/filt_humann3.py 'HUMAnN3_results/HUMAnN3_merged_genefamilies.tsv' 'HUMAnN3_results/genefamilies_filtered.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize to relative abundance with  `total sum scaling (TSS)`-style normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading table from: HUMAnN3_results/genefamilies_filtered.tsv\n"
     ]
    }
   ],
   "source": [
    "! humann_renorm_table --input HUMAnN3_results/genefamilies_filtered.tsv --units relab --output HUMAnN3_results/genefamilies_filtered_normalized.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2.2.3. Comparative statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy metadata from `02_Diff_analysis`<br>\n",
    "It was created during **`Part 1.4. Create metadata`** step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cp ../02_Diff_analysis/metadata.csv ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Part 2.2.3.1. Differential Pathway Abundance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose `HUMAnN3_results/pathabundance_filtered_normalized.tsv` and convert it to `.csv` for better input to `MaAsLin2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transposed file saved to: HUMAnN3_results/pathabundance_transposed.csv\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "# {path_to_script} {path_to_input_file} {path_to_output_file}\n",
    "%run scripts/transpose_humann.py 'HUMAnN3_results/pathabundance_filtered_normalized.tsv' 'HUMAnN3_results/pathabundance_transposed.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `MaAsLin2`\n",
    "\n",
    ">Please notice: this `scripts/MaAsLin2.R` differs from `scripts/MaAsLin2.R` script in `02_Diff_analysis`. This version of the script uses `normalization  = \"NONE\"` as there is no need to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Usage\n",
    "# {path_to_script} {path_to_metadata} {path_to_counts} {path_to_output}\n",
    "Rscript.exe scripts/MaAsLin2.R metadata.csv HUMAnN3_results/pathabundance_transposed.csv MaAsLin2_on_HUMAnN3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>metadata</th>\n",
       "      <th>value</th>\n",
       "      <th>coef</th>\n",
       "      <th>stderr</th>\n",
       "      <th>N</th>\n",
       "      <th>N.not.0</th>\n",
       "      <th>pval</th>\n",
       "      <th>qval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [feature, metadata, value, coef, stderr, N, N.not.0, pval, qval]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MaAsLin2_on_HUMAnN3_results = pd.read_csv('MaAsLin2_on_HUMAnN3_results/significant_results.tsv', sep='\\t')\n",
    "MaAsLin2_on_HUMAnN3_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Part 2.2.4. Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualize only `HUMAnN3_results/pathabundance_filtered_normalized.tsv` file because:\n",
    "- UniRef90 database found more than 10K gene families! It is impossible to visualize.\n",
    "- `MaAsLin2` did not found any significant results in differential pathway abundance. Volcano plot cannot be implemented in this case because it makes no sense in terms of pathways. According to the official [`bioBakery` guideline](https://github.com/biobakery/biobakery/wiki/humann3#5-plotting-stratified-functions), if `MaAsLin2` finds something in `HUMAnN3` pathabund output it must be visualized as `humann_barplot`. Yet we have nothing to visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please open `RStudio` and go through  `HUMAnN3_heatmaps_journal.R` script.<br>\n",
    "There are a lot of manual adjustments to the plots to make it executable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Part 2.3. `KEGG` pathways completeness with `eggNOG-mapper` and `KEGGaNOG`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`emapKEGG_pipeline` is a Snakemake pipeline that runs `eggNOG-mapper` & `KEGGaNOG` through all 10 filtered MAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! snakemake -s emapper_pipeline --use-conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the result of this pipeline outputs are stored in `eggNOG` folder:\n",
    "- `{sample}`:\n",
    "    - `{prefix}.emapper.annotations`\n",
    "    - `{prefix}.emapper.genepred.fasta`\n",
    "    - `{prefix}.emapper.genepred.gff`\n",
    "    - `{prefix}.emapper.hits`\n",
    "    - `{prefix}.emapper.seed_orthologs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the heatmap of `KEGG` pathways completenesses. For this we need a `.txt` file with file locations of `{prefix}.emapper.annotations` files. Let's create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'annotations.txt' has been created in the 'eggNOG' directory.\n"
     ]
    }
   ],
   "source": [
    "# Define the directory and file path\n",
    "directory = \"eggNOG\"\n",
    "file_path = os.path.join(directory, \"annotations.txt\")\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Define the content to write to the file\n",
    "content = \"\"\"\\\n",
    "eggNOG/D1/VM1.emapper.annotations\n",
    "eggNOG/D2/VM2.emapper.annotations\n",
    "eggNOG/D3/VM3.emapper.annotations\n",
    "eggNOG/D5/VM5.emapper.annotations\n",
    "eggNOG/P1/NN1.emapper.annotations\n",
    "eggNOG/P2/NN2.emapper.annotations\n",
    "eggNOG/P3/NN3.emapper.annotations\n",
    "eggNOG/P4/NN4.emapper.annotations\n",
    "eggNOG/P5/NN5.emapper.annotations\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to the file\n",
    "with open(file_path, \"w\") as f:\n",
    "    f.write(content)\n",
    "\n",
    "print(f\"'annotations.txt' has been created in the '{directory}' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is ready for launching `KEGGaNOG`.<br>\n",
    "**NB!** It uses `python 3.6`, so please use another `conda env` (`kegganog.yaml`) as the `kernel` for the cell below (or run it in your `terminal`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! KEGGaNOG --multi -i eggNOG/annotations.txt -o KEGGaNOG -dpi 600 -g"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mags",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
